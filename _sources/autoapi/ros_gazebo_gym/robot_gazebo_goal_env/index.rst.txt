:py:mod:`ros_gazebo_gym.robot_gazebo_goal_env`
==============================================

.. py:module:: ros_gazebo_gym.robot_gazebo_goal_env

.. autoapi-nested-parse::

   The Gazebo GOAL environment is mainly used to connect the simulated Gym GOAL
   environment to the Gazebo simulator. It takes care of the resets of the simulator after
   each step or the resets of the controllers (if needed), it also takes care of all the
   steps that need to be done on the simulator when doing a training step or a training
   reset (typical steps in the reinforcement learning loop).

   .. important::
       This class is similar to the
       :class:`~ros_gazebo_gym.robot_gazebo_env.RobotGazeboEnv` class but now instead of
       the :class:`gym.Env` class the :class:`gym.GoalEnv` class is used as the superclass.
       As a result, a goal-based environment is created. You should use this goal based
       Gazebo environment when you are working with RL algorithms that require a spare
       reward space (i.e. `Hindsight Experience Replay (HER)
       <https://stable-baselines.readthedocs.io/en/master/modules/her.html>`_).

       This goal-based environment just like any regular gymnasium environment, but it
       imposes a required structure on the observation_space. More concretely, the
       observation space is required to contain at least three elements, namely
       ``observation``, ``desired_goal``, and  ``achieved_goal``. Here, `desired_goal`
       specifies the goal that the agent should attempt to achieve. `achieved_goal` is the
       goal that it currently achieved instead. `observation` contains the actual
       observations of the environment as per usual.

       Further with this goal env, not the cumulative cost is published to the
       ``/ros_gazebo_gym/reward`` reward topic during the env reset, like was the case in
       the :class:`~ros_gazebo_gym.robot_gazebo_env.RobotGazeboEnv`, but the cost at each
       step.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   ros_gazebo_gym.robot_gazebo_goal_env.RobotGazeboGoalEnv




.. py:class:: RobotGazeboGoalEnv(robot_name_space, reset_controls, controllers_list=None, reset_robot_pose=False, reset_world_or_sim='SIMULATION', log_reset=True, pause_simulation=False, publish_rviz_training_info_overlay=False)


   Bases: :py:obj:`gymnasium_robotics.GoalEnv`

   Connects the simulated GOAL gymnasium environment to the gazebo simulator.

   .. attribute:: gazebo

      Gazebo connector which can be used to interact with the gazebo simulation.

      :type: :class:`~ros_gazebo_gym.core.gazebo_connection.GazeboConnection`

   .. attribute:: episode_num

      The current episode.

      :type: int

   .. attribute:: step_num

      The current step.

      :type: int

   .. attribute:: step_reward

      The reward achieved by the current step.

      :type: float

   Initiate the RobotGazebo environment instance.

   :param robot_name_space: The namespace the robot is on.
   :type robot_name_space: str
   :param reset_controls: Whether the controllers should be reset when the
                          :meth:`RobotGazeboEnv.reset` method is called.
   :type reset_controls: bool
   :param controllers_list: A list with currently available
                            controllers to look for. Defaults to ``None``, which means that the
                            class will try to retrieve all the running controllers.
   :type controllers_list: list, optional
   :param reset_robot_pose: Boolean specifying whether to reset the robot pose
                            when the simulation is reset.
   :type reset_robot_pose: bool
   :param reset_world_or_sim: Whether you want to reset the whole
                              simulation "SIMULATION" at startup or only the world "WORLD" (object
                              positions). Defaults to "SIMULATION".
   :type reset_world_or_sim: str, optional
   :param log_reset: Whether we want to print a log statement when
                     the world/simulation is reset. Defaults to ``True``.
   :type log_reset: bool, optional
   :param pause_sim: Whether the simulation should be paused after
                     each step (i.e. after each action). Defaults to ``False``.
   :type pause_sim: bool, optional
   :param publish_rviz_training_info_overlay: Whether a RViz overlay
                                              should be published with the training results. Defaults to ``False``.
   :type publish_rviz_training_info_overlay: bool, optional

   .. py:method:: step(action)

      Function executed each time step. Here we get the action execute it in a
      time step and retrieve the observations generated by that action. We also
      publish the step reward on the ``/ros_gazebo_gym/reward`` topic.

      :param action: The action we want to perform in the environment.
      :type action: numpy.ndarray

      :returns:

                tuple containing:

                    - obs (:obj:`np.ndarray`): Environment observation.
                    - cost (:obj:`float`): Cost of the action.
                    - terminated (:obj:`bool`): Whether the episode is terminated.
                    - truncated (:obj:`bool`): Whether the episode was truncated. This
                      value is set by wrappers when for example a time limit is reached or
                      the agent goes out of bounds.
                    - info (:obj:`dict`): Additional information about the environment.
      :rtype: (tuple)

      .. note::
          Here we should convert the action num to movement action, execute the action
          in the simulation and get the observations result of performing that action.


   .. py:method:: reset(seed=None, options=None)

      Function executed when resetting the environment.

      :param seed: The seed to use for the random number generator.
                   Defaults to ``None``.
      :type seed: int, optional
      :param options: The options to pass to the environment. Defaults
                      to ``None``.
      :type options: dict, optional

      :returns:

                tuple containing:

                    - obs (:obj:`numpy.ndarray`): The current state
                    - info_dict (:obj:`dict`): Dictionary with additional information.
      :rtype: (tuple)


   .. py:method:: close()

      Function executed when closing the environment. Use it for closing GUIS and
      other systems that need closing.


   .. py:method:: render(render_mode='human')

      Overload render method since rendering is handled in Gazebo.


   .. py:method:: pause_controllers(controllers_list=None, filter_list=[])

      Pauses the controllers.

      :param controller_list: The controllers you want to pause.
                              Defaults to ``None``, which means that the class will pause all the
                              running controllers.
      :type controller_list: list, optional
      :param filter_list: The controllers you want to ignore when
                          pausing. Defaults to ``[]``.
      :type filter_list: list, optional


   .. py:method:: unpause_controllers()

      Un-pauses the paused controllers.



